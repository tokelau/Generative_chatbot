{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOrW3ykq5OBqQmPhe8bOhRs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Запустим инференс базовой и обученной модели, чтобы позже оценить результаты в ноутбуке eval.ipynb. Также напишем функцию инференса, чтобы можно было задавать модели любые вопросы"],"metadata":{"id":"HtFcGqsO-Z3n"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xt05mMiEZLm8","executionInfo":{"status":"ok","timestamp":1742672112236,"user_tz":-480,"elapsed":22531,"user":{"displayName":"Nastya","userId":"11252779665510215149"}},"outputId":"64888923-8686-4fc5-8858-8036ead4d290"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv('/content/drive/MyDrive/Генерация в NLP/hw_task_2/data/house_answers.csv')\n","df = df[['line', 'response']].rename(columns={'line': 'instruction', 'response': 'output'})"],"metadata":{"id":"ihF8aK7oPNsO","executionInfo":{"status":"ok","timestamp":1742672119561,"user_tz":-480,"elapsed":7324,"user":{"displayName":"Nastya","userId":"11252779665510215149"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Базовая модель"],"metadata":{"id":"G-uWP1_WuS4B"}},{"cell_type":"code","source":["%%capture\n","!pip install bitsandbytes"],"metadata":{"id":"Dc01FASvuoT_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n","from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n","import torch\n","\n","# Загружаем токенизатор и модель\n","model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n","# tokenizer.pad_token = tokenizer.eos_token  # LLaMA не имеет pad_token по умолчанию\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    load_in_4bit=True,\n","    device_map=\"auto\",\n","    torch_dtype=torch.float16\n",")\n","\n","# 3. Готовим модель к дообучению с LoRA\n","model = prepare_model_for_kbit_training(model)\n","\n","lora_config = LoraConfig(\n","    r=8,\n","    lora_alpha=16,\n","    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","model = get_peft_model(model, lora_config)"],"metadata":{"id":"VaqwAeAPlIh7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def get_model_answer(prompt):\n","#     messages = [\n","#         {\"role\": \"system\", \"content\": \"Answer like Dr.House\"},\n","#         {\"role\": \"user\", \"content\": prompt}\n","#     ]\n","#     text = tokenizer.apply_chat_template(\n","#         messages,\n","#         tokenize=False,\n","#         add_generation_prompt=True\n","#     )\n","#     model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n","\n","#     generated_ids = model.generate(\n","#         **model_inputs,\n","#         max_new_tokens=32\n","#     )\n","#     generated_ids = [\n","#         output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n","#     ]\n","\n","#     response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","#     return response\n","\n","\n","def prepare_df(prompt):\n","    messages = [\n","        {\"role\": \"system\", \"content\": \"Answer like Dr.House\"},\n","        {\"role\": \"user\", \"content\": prompt}\n","    ]\n","    text = tokenizer.apply_chat_template(\n","        messages,\n","        tokenize=False,\n","        add_generation_prompt=True\n","    )\n","    return text"],"metadata":{"id":"wBLDUCjKuWlK","executionInfo":{"status":"aborted","timestamp":1742670982580,"user_tz":-480,"elapsed":4,"user":{"displayName":"Nastya","userId":"11252779665510215149"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get_model_answer(\"Hi\")"],"metadata":{"id":"6fsvunCDuv5l","executionInfo":{"status":"aborted","timestamp":1742670982581,"user_tz":-480,"elapsed":26988,"user":{"displayName":"Nastya","userId":"11252779665510215149"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"Ev7iLpRk0p7c","executionInfo":{"status":"aborted","timestamp":1742670982582,"user_tz":-480,"elapsed":26987,"user":{"displayName":"Nastya","userId":"11252779665510215149"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","df['prepared_instruction'] = df['instruction'].apply(prepare_df)"],"metadata":{"id":"Z46eloUnhrLy","executionInfo":{"status":"aborted","timestamp":1742670982582,"user_tz":-480,"elapsed":26984,"user":{"displayName":"Nastya","userId":"11252779665510215149"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["texts = df['prepared_instruction'].to_list()"],"metadata":{"id":"t5yLd5BljmRH","executionInfo":{"status":"aborted","timestamp":1742670982583,"user_tz":-480,"elapsed":26985,"user":{"displayName":"Nastya","userId":"11252779665510215149"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","\n","model.eval()\n","chunk_size = 10\n","\n","answers = []\n","for step in tqdm(range(0, len(texts), chunk_size)):\n","  texts_chunk = texts[step:step + chunk_size]\n","  model_inputs = tokenizer(texts_chunk, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512, padding_side='left').to(model.device)\n","\n","  generated_ids = model.generate(\n","      **model_inputs,\n","      max_new_tokens=32\n","  )\n","  generated_ids = [\n","      output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n","  ]\n","\n","  response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n","  answers.extend(response)"],"metadata":{"id":"zLv8vLxCilid","executionInfo":{"status":"aborted","timestamp":1742670982589,"user_tz":-480,"elapsed":26989,"user":{"displayName":"Nastya","userId":"11252779665510215149"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['base_model_answers'] = answers"],"metadata":{"id":"sU8uTn_PkgsH","executionInfo":{"status":"aborted","timestamp":1742670982590,"user_tz":-480,"elapsed":26990,"user":{"displayName":"Nastya","userId":"11252779665510215149"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Обученная модель"],"metadata":{"id":"T7N_4-J3u1UB"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n","from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n","import torch\n","\n","# Загружаем токенизатор и модель\n","# model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n","# tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n","\n","finetuned_model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    load_in_4bit=True,\n","    device_map=\"auto\",\n","    torch_dtype=torch.float16\n",")\n","\n","# 3. Готовим модель к дообучению с LoRA\n","finetuned_model = prepare_model_for_kbit_training(finetuned_model)\n","\n","lora_config = LoraConfig(\n","    r=8,\n","    lora_alpha=16,\n","    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","finetuned_model = get_peft_model(finetuned_model, lora_config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yQuBmnibw6QN","executionInfo":{"status":"ok","timestamp":1742671240173,"user_tz":-480,"elapsed":2284,"user":{"displayName":"Nastya","userId":"11252779665510215149"}},"outputId":"9fbc9599-d1e0-4431-dd51-26a4fcb3353b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"]}]},{"cell_type":"code","source":["finetuned_model.load_state_dict(torch.load('/content/drive/MyDrive/Генерация в NLP/hw_task_2/models/qwen_House_1.pth'), strict=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BEl0fRxKux3U","executionInfo":{"status":"ok","timestamp":1742671253722,"user_tz":-480,"elapsed":13547,"user":{"displayName":"Nastya","userId":"11252779665510215149"}},"outputId":"7966ba48-d15c-49fd-de4d-ccdee61a3c0a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-8-02964f1f858b>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  finetuned_model.load_state_dict(torch.load('/content/drive/MyDrive/Генерация в NLP/hw_task_2/models/qwen_House_1.pth'), strict=False)\n"]},{"output_type":"execute_result","data":{"text/plain":["_IncompatibleKeys(missing_keys=[], unexpected_keys=['base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.0.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.0.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.0.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.0.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.0.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.0.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.0.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.0.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.0.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.1.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.1.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.1.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.1.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.1.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.1.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.1.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.1.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.1.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.2.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.2.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.2.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.2.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.2.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.2.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.2.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.2.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.2.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.3.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.3.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.3.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.3.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.3.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.3.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.3.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.3.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.3.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.4.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.4.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.4.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.4.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.4.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.4.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.4.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.4.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.4.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.5.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.5.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.5.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.5.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.5.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.5.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.5.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.5.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.5.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.6.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.6.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.6.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.6.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.6.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.6.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.6.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.6.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.6.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.7.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.7.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.7.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.7.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.7.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.7.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.7.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.7.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.7.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.8.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.8.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.8.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.8.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.8.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.8.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.8.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.8.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.8.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.9.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.9.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.9.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.9.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.9.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.9.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.9.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.9.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.9.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.10.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.10.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.10.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.10.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.10.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.10.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.10.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.10.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.10.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.11.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.11.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.11.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.11.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.11.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.11.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.11.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.11.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.11.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.12.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.12.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.12.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.12.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.12.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.12.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.12.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.12.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.12.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.13.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.13.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.13.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.13.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.13.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.13.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.13.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.13.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.13.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.14.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.14.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.14.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.14.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.14.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.14.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.14.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.14.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.14.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.15.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.15.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.15.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.15.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.15.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.15.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.15.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.15.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.15.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.16.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.16.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.16.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.16.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.16.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.16.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.16.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.16.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.16.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.17.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.17.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.17.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.17.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.17.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.17.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.17.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.17.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.17.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.18.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.18.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.18.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.18.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.18.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.18.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.18.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.18.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.18.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.19.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.19.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.19.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.19.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.19.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.19.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.19.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.19.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.19.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.20.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.20.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.20.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.20.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.20.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.20.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.20.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.20.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.20.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.21.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.21.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.21.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.21.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.21.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.21.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.21.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.21.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.21.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.22.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.22.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.22.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.22.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.22.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.22.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.22.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.22.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.22.mlp.down_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight.absmax', 'base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight.absmax', 'base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight.absmax', 'base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.absmax', 'base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.quant_map', 'base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.23.mlp.gate_proj.weight.absmax', 'base_model.model.model.layers.23.mlp.gate_proj.weight.quant_map', 'base_model.model.model.layers.23.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.23.mlp.up_proj.weight.absmax', 'base_model.model.model.layers.23.mlp.up_proj.weight.quant_map', 'base_model.model.model.layers.23.mlp.up_proj.weight.quant_state.bitsandbytes__fp4', 'base_model.model.model.layers.23.mlp.down_proj.weight.absmax', 'base_model.model.model.layers.23.mlp.down_proj.weight.quant_map', 'base_model.model.model.layers.23.mlp.down_proj.weight.quant_state.bitsandbytes__fp4'])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["from tqdm import tqdm\n","\n","finetuned_model.eval()\n","chunk_size = 10\n","\n","ft_answers = []\n","for step in tqdm(range(0, len(texts), chunk_size)):\n","  texts_chunk = texts[step:step + chunk_size]\n","  model_inputs = tokenizer(texts_chunk, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512, padding_side='left').to(model.device)\n","\n","  generated_ids = finetuned_model.generate(\n","      **model_inputs,\n","      max_new_tokens=32\n","  )\n","  generated_ids = [\n","      output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n","  ]\n","\n","  response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n","  ft_answers.extend(response)"],"metadata":{"id":"8kKfzGTtpTN3","executionInfo":{"status":"aborted","timestamp":1742670982592,"user_tz":-480,"elapsed":26987,"user":{"displayName":"Nastya","userId":"11252779665510215149"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['finetuned_model_answers'] = ft_answers"],"metadata":{"id":"4CR9-PlJpb2m","executionInfo":{"status":"aborted","timestamp":1742670982592,"user_tz":-480,"elapsed":26987,"user":{"displayName":"Nastya","userId":"11252779665510215149"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"WvuVaG3iyLLs","executionInfo":{"status":"aborted","timestamp":1742670982616,"user_tz":-480,"elapsed":27010,"user":{"displayName":"Nastya","userId":"11252779665510215149"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.to_csv('/content/drive/MyDrive/Генерация в NLP/hw_task_2/data/answers.csv', index=False)"],"metadata":{"id":"gLpZTODpyMPG","executionInfo":{"status":"aborted","timestamp":1742670982617,"user_tz":-480,"elapsed":27010,"user":{"displayName":"Nastya","userId":"11252779665510215149"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Простая функция инференса"],"metadata":{"id":"XrJWhZJHOpnF"}},{"cell_type":"code","source":["def get_model_answer(model, prompt):\n","    messages = [\n","        {\"role\": \"system\", \"content\": \"Answer like Dr.House\"},\n","        {\"role\": \"user\", \"content\": prompt}\n","    ]\n","    text = tokenizer.apply_chat_template(\n","        messages,\n","        tokenize=False,\n","        add_generation_prompt=True\n","    )\n","    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n","\n","    generated_ids = model.generate(\n","        **model_inputs,\n","        max_new_tokens=32\n","    )\n","    generated_ids = [\n","        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n","    ]\n","\n","    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","    return response"],"metadata":{"id":"CUt3zf1kOx5T","executionInfo":{"status":"ok","timestamp":1742671374326,"user_tz":-480,"elapsed":24,"user":{"displayName":"Nastya","userId":"11252779665510215149"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["get_model_answer(model, 'Hi')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"tdDp6BNJQZD9","executionInfo":{"status":"ok","timestamp":1742671377047,"user_tz":-480,"elapsed":2558,"user":{"displayName":"Nastya","userId":"11252779665510215149"}},"outputId":"46019fcc-7a3f-475a-c5d0-e212aad623da"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Hello! How can I assist you today?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["get_model_answer(finetuned_model, 'Hi')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"tr93XsZdQjt9","executionInfo":{"status":"ok","timestamp":1742671394955,"user_tz":-480,"elapsed":1282,"user":{"displayName":"Nastya","userId":"11252779665510215149"}},"outputId":"4a8d18c1-2ba6-4dae-b0fd-eb69f3a78a7b"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' What are you going to do?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["!pip freeze > requirements.txt"],"metadata":{"id":"wNqVg7HBTxqW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FlwJg1hCWZox"},"execution_count":null,"outputs":[]}]}